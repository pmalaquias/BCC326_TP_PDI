{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4f255d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro: Não foi possível inspecionar a pasta. Verifique se o dataset foi baixado e descompactado corretamente.\n",
      "Detalhes do erro: list index out of range\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "CAMINHO_BASE = '.'\n",
    "MPIIGAZE_DIR = os.path.join(CAMINHO_BASE, 'mpiigaze_real', 'MPIIGaze')\n",
    "REAL_DATA_ROOT = os.path.join(MPIIGAZE_DIR, 'Data', 'Normalized')\n",
    "\n",
    "try:\n",
    "    # Pegar o primeiro usuário e o primeiro dia\n",
    "    user_to_check = sorted([d for d in os.listdir(REAL_DATA_ROOT) if d.startswith('p')])[0]\n",
    "    day_to_check = sorted([d for d in os.listdir(os.path.join(REAL_DATA_ROOT, user_to_check)) if os.path.isdir(os.path.join(REAL_DATA_ROOT, user_to_check, d))])[0]\n",
    "    \n",
    "    # Caminho completo para a pasta de dia\n",
    "    day_dir_to_check = os.path.join(REAL_DATA_ROOT, user_to_check, day_to_check)\n",
    "\n",
    "    print(f\"Listando o conteúdo da pasta de dia: {day_dir_to_check}\")\n",
    "    \n",
    "    # Listar o conteúdo do diretório de dia\n",
    "    for item in os.listdir(day_dir_to_check):\n",
    "        print(f\"  - {item}\")\n",
    "\n",
    "except (IndexError, FileNotFoundError) as e:\n",
    "    print(\"Erro: Não foi possível inspecionar a pasta. Verifique se o dataset foi baixado e descompactado corretamente.\")\n",
    "    print(f\"Detalhes do erro: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb5d4fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'Python 3.11.13' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import TimeDistributed, Conv2D, MaxPooling2D, Flatten, LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88527481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configurações de Caminho (Definitivas) ---\n",
    "CAMINHO_BASE = '.'\n",
    "MODELO_SALVO = os.path.join(CAMINHO_BASE, 'gaze_attention_model.keras')\n",
    "LABELS_FILE_SYNTHETIC = os.path.join(CAMINHO_BASE, 'gaze_labels.csv')\n",
    "\n",
    "# --- Caminho Corrigido para os Dados Reais do MPIIGaze ---\n",
    "MPIIGAZE_DIR = os.path.join(CAMINHO_BASE, 'mpiigaze_real', 'MPIIGaze')\n",
    "REAL_DATA_ROOT = os.path.join(MPIIGAZE_DIR, 'Data', 'Normalized')\n",
    "\n",
    "# Tamanho da imagem redimensionada\n",
    "IMG_SIZE = (64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01427006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificando se o dataset MPIIGaze já existe...\n",
      "Processando dados do MPIIGaze...\n",
      "Dados reais processados. Total de imagens: 0\n",
      "Nenhuma imagem foi processada. Verifique se o nome das subpastas é 'image' e se os nomes dos arquivos são '0.jpg', '1.jpg', etc.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 58\u001b[0m\n\u001b[0;32m     55\u001b[0m     exit()\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# O MPIIGaze é um dataset grande, vamos usar uma pequena parte para o ajuste fino.\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m X_real_train, X_real_test, y_real_train, y_real_test \u001b[38;5;241m=\u001b[39m train_test_split(X_real, y_real, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2851\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2848\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m   2850\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m-> 2851\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2852\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[0;32m   2853\u001b[0m )\n\u001b[0;32m   2855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m   2856\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\pedro\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2481\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2478\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[0;32m   2480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2481\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2482\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2483\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2484\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[0;32m   2485\u001b[0m     )\n\u001b[0;32m   2487\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(\"Verificando se o dataset MPIIGaze já existe...\")\n",
    "if not os.path.exists(MPIIGAZE_DIR):\n",
    "    print(\"Dataset MPIIGaze não encontrado. Por favor, baixe e descompacte o arquivo na raiz do seu projeto.\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    import scipy.io as sio\n",
    "except ImportError:\n",
    "    print(\"A biblioteca scipy não está instalada. Instalando...\")\n",
    "    !pip install scipy\n",
    "    import scipy.io as sio\n",
    "\n",
    "print(\"Processando dados do MPIIGaze...\")\n",
    "X_real = []\n",
    "y_real = []\n",
    "\n",
    "if os.path.exists(REAL_DATA_ROOT):\n",
    "    USER_NAMES = sorted([d for d in os.listdir(REAL_DATA_ROOT) if d.startswith('p')])\n",
    "    for user in USER_NAMES:\n",
    "        user_dir = os.path.join(REAL_DATA_ROOT, user)\n",
    "        day_folders = sorted([d for d in os.listdir(user_dir) if os.path.isdir(os.path.join(user_dir, d))])\n",
    "        \n",
    "        for day in day_folders:\n",
    "            day_dir = os.path.join(user_dir, day)\n",
    "            \n",
    "            annotation_file = os.path.join(day_dir, 'annotation.mat')\n",
    "            images_folder = os.path.join(day_dir, 'image') # Caminho correto para as imagens\n",
    "\n",
    "            if os.path.exists(annotation_file) and os.path.exists(images_folder):\n",
    "                mat_data = sio.loadmat(annotation_file)\n",
    "                gaze_labels = mat_data['gaze']\n",
    "                gaze_threshold = 0.1\n",
    "                labels = np.linalg.norm(gaze_labels, axis=1) < gaze_threshold\n",
    "                \n",
    "                # Nomes de arquivos de imagem no formato 0.jpg, 1.jpg, etc.\n",
    "                image_filenames = sorted([f for f in os.listdir(images_folder) if f.endswith('.jpg')])\n",
    "                \n",
    "                # Certifique-se de que o número de imagens e rótulos corresponde\n",
    "                if len(image_filenames) == len(labels):\n",
    "                    for i, image_filename in enumerate(image_filenames):\n",
    "                        image_path = os.path.join(images_folder, image_filename)\n",
    "                        img = cv2.imread(image_path)\n",
    "                        if img is not None:\n",
    "                            img_resized = cv2.resize(img, IMG_SIZE)\n",
    "                            img_normalized = img_resized.astype('float32') / 255.0\n",
    "                            X_real.append(img_normalized)\n",
    "                            y_real.append(labels[i])\n",
    "\n",
    "X_real = np.array(X_real)\n",
    "y_real = np.array(y_real)\n",
    "print(f\"Dados reais processados. Total de imagens: {len(X_real)}\")\n",
    "\n",
    "if len(X_real) == 0:\n",
    "    print(\"Nenhuma imagem foi processada. Verifique se o nome das subpastas é 'image' e se os nomes dos arquivos são '0.jpg', '1.jpg', etc.\")\n",
    "    exit()\n",
    "\n",
    "# O MPIIGaze é um dataset grande, vamos usar uma pequena parte para o ajuste fino.\n",
    "X_real_train, X_real_test, y_real_train, y_real_test = train_test_split(X_real, y_real, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "171fc743",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Lista todos os dispositivos disponíveis (CPU e GPU)\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(tf.config.list_physical_devices(\u001b[33m'\u001b[39m\u001b[33mGPU\u001b[39m\u001b[33m'\u001b[39m))\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Lista todos os dispositivos disponíveis (CPU e GPU)\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Confirma se o TensorFlow está compilado com suporte a GPU\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "homl3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
